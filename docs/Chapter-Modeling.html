<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Predicting marketable tuber yield | Nutrient Diagnosis Of Potato</title>
  <meta name="description" content="This is a example of using the bookdown package to write a book that describ the statistical computations of my PhD Project, for publication on Github. The output format choosed is bookdown::gitbook. Next features are set out for after (bibliography and links)." />
  <meta name="generator" content="bookdown 0.10 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Predicting marketable tuber yield | Nutrient Diagnosis Of Potato" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a example of using the bookdown package to write a book that describ the statistical computations of my PhD Project, for publication on Github. The output format choosed is bookdown::gitbook. Next features are set out for after (bibliography and links)." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Predicting marketable tuber yield | Nutrient Diagnosis Of Potato" />
  
  <meta name="twitter:description" content="This is a example of using the bookdown package to write a book that describ the statistical computations of my PhD Project, for publication on Github. The output format choosed is bookdown::gitbook. Next features are set out for after (bibliography and links)." />
  

<meta name="author" content="zcoulibali" />


<meta name="date" content="2019-06-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chapter-Clustering.html">
<link rel="next" href="Chapter-Perturbation-vector.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Data processing</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#Objective"><i class="fa fa-check"></i><b>1.1</b> Ojective</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#useful-libraries-for-data-handling"><i class="fa fa-check"></i><b>1.2</b> Useful libraries for data handling</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#quebec-potato-data-set"><i class="fa fa-check"></i><b>1.3</b> Qu√©bec potato data set</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#selection-of-useful-variables"><i class="fa fa-check"></i><b>1.4</b> Selection of useful variables</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#arranging-the-data-frame"><i class="fa fa-check"></i><b>1.5</b> Arranging the data frame</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#cultivars-classes-correction."><i class="fa fa-check"></i><b>1.6</b> Cultivars classes correction.</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#summarise-and-backup"><i class="fa fa-check"></i><b>1.7</b> Summarise and backup</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chapter-Clustering.html"><a href="Chapter-Clustering.html"><i class="fa fa-check"></i><b>2</b> Cluster analysis of potato cultivars</a><ul>
<li class="chapter" data-level="2.1" data-path="Chapter-Clustering.html"><a href="Chapter-Clustering.html#objective"><i class="fa fa-check"></i><b>2.1</b> Objective</a></li>
<li class="chapter" data-level="2.2" data-path="Chapter-Clustering.html"><a href="Chapter-Clustering.html#useful-libraries-and-custom-functions"><i class="fa fa-check"></i><b>2.2</b> Useful libraries and custom functions</a></li>
<li class="chapter" data-level="2.3" data-path="Chapter-Clustering.html"><a href="Chapter-Clustering.html#leaves-processed-compositions-data-set"><i class="fa fa-check"></i><b>2.3</b> Leaves processed compositions data set</a></li>
<li class="chapter" data-level="2.4" data-path="Chapter-Clustering.html"><a href="Chapter-Clustering.html#high-yielders-delimiter"><i class="fa fa-check"></i><b>2.4</b> High yielders delimiter</a></li>
<li class="chapter" data-level="2.5" data-path="Chapter-Clustering.html"><a href="Chapter-Clustering.html#clr-centroids-computation"><i class="fa fa-check"></i><b>2.5</b> <code>clr</code> centroids computation</a></li>
<li class="chapter" data-level="2.6" data-path="Chapter-Clustering.html"><a href="Chapter-Clustering.html#axis-reduction"><i class="fa fa-check"></i><b>2.6</b> Axis reduction</a></li>
<li class="chapter" data-level="2.7" data-path="Chapter-Clustering.html"><a href="Chapter-Clustering.html#cascade-k-means-clustering"><i class="fa fa-check"></i><b>2.7</b> Cascade K Means clustering</a></li>
<li class="chapter" data-level="2.8" data-path="Chapter-Clustering.html"><a href="Chapter-Clustering.html#arranging-data-for-machine-learning"><i class="fa fa-check"></i><b>2.8</b> Arranging data for Machine Learning</a></li>
<li class="chapter" data-level="2.9" data-path="Chapter-Clustering.html"><a href="Chapter-Clustering.html#clr-x-ionomics-groups-interactions-effects"><i class="fa fa-check"></i><b>2.9</b> clr X ionomics groups interactions effects</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chapter-Modeling.html"><a href="Chapter-Modeling.html"><i class="fa fa-check"></i><b>3</b> Predicting marketable tuber yield</a><ul>
<li class="chapter" data-level="3.1" data-path="Chapter-Modeling.html"><a href="Chapter-Modeling.html#load-data-file"><i class="fa fa-check"></i><b>3.1</b> Load data file</a></li>
<li class="chapter" data-level="3.2" data-path="Chapter-Modeling.html"><a href="Chapter-Modeling.html#machine-learning"><i class="fa fa-check"></i><b>3.2</b> Machine learning</a></li>
<li class="chapter" data-level="3.3" data-path="Chapter-Modeling.html"><a href="Chapter-Modeling.html#assessing-goodness-of-fit"><i class="fa fa-check"></i><b>3.3</b> Assessing goodness of fit</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chapter-Perturbation-vector.html"><a href="Chapter-Perturbation-vector.html"><i class="fa fa-check"></i><b>4</b> Perturbation vector theory</a><ul>
<li class="chapter" data-level="4.1" data-path="Chapter-Perturbation-vector.html"><a href="Chapter-Perturbation-vector.html#dissimilarity-index-between-compositions"><i class="fa fa-check"></i><b>4.1</b> Dissimilarity index between compositions</a></li>
<li class="chapter" data-level="4.2" data-path="Chapter-Perturbation-vector.html"><a href="Chapter-Perturbation-vector.html#rebalancing-a-misbalanced-sample-by-perturbation"><i class="fa fa-check"></i><b>4.2</b> Rebalancing a misbalanced sample by perturbation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Nutrient Diagnosis Of Potato</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Chapter-Modeling" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Predicting marketable tuber yield</h1>
<div id="load-data-file" class="section level2">
<h2><span class="header-section-number">3.1</span> Load data file</h2>
<p>Load data file <code>data_ionome.csv</code> saved from previous cluster analysis.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)    <span class="co"># &#39;diplyr&#39; and &#39;ggplot2&#39;</span>
<span class="kw">library</span>(<span class="st">&#39;extrafont&#39;</span>)    <span class="co"># Changing Fonts for Graphs</span>
df =<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&#39;output/dfml.csv&#39;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">colnames</span>(df)[<span class="kw">colnames</span>(df)<span class="op">==</span><span class="st">&quot;ionomicGroup&quot;</span>] &lt;-<span class="st"> &quot;group_i&quot;</span> <span class="co"># make simplier</span>
df<span class="op">$</span>group_i =<span class="st"> </span><span class="kw">factor</span>(df<span class="op">$</span>group_i)
df<span class="op">$</span>yieldClass =<span class="st"> </span><span class="kw">factor</span>(df<span class="op">$</span>yieldClass)

clr_no &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;clr_N&quot;</span>, <span class="st">&quot;clr_P&quot;</span>, <span class="st">&quot;clr_K&quot;</span>, <span class="st">&quot;clr_Mg&quot;</span>, <span class="st">&quot;clr_Ca&quot;</span>, <span class="st">&quot;clr_Fv&quot;</span>)
clrNo &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;clrN&quot;</span>, <span class="st">&quot;clrP&quot;</span>, <span class="st">&quot;clrK&quot;</span>, <span class="st">&quot;clrMg&quot;</span>, <span class="st">&quot;clrCa&quot;</span>, <span class="st">&quot;clrFv&quot;</span>)
<span class="kw">colnames</span>(df)[<span class="kw">which</span>(<span class="kw">names</span>(df) <span class="op">%in%</span><span class="st"> </span>clr_no)] &lt;-<span class="st"> </span>clrNo

df.sc =<span class="st"> </span>df <span class="co"># copy</span>
df.sc[, clrNo] &lt;-<span class="st"> </span><span class="kw">apply</span>(df.sc[, clrNo], <span class="dv">2</span>, scale) <span class="co"># scale clr coordinates</span></code></pre></div>
<p>Dummy code maturity order and ionomic group.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">if</span>(<span class="st">&quot;Maturity5&quot;</span> <span class="op">%in%</span><span class="st"> </span><span class="kw">colnames</span>(df.sc)) {
  df.sc<span class="op">$</span>Maturity5 &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="kw">ordered</span>(<span class="kw">factor</span>(df.sc<span class="op">$</span>Maturity5)))[, <span class="dv">2</span>]
}

<span class="cf">if</span>(<span class="st">&quot;group_i&quot;</span> <span class="op">%in%</span><span class="st"> </span><span class="kw">colnames</span>(df.sc)) {
  df.sc<span class="op">$</span>group_i &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="kw">ordered</span>(<span class="kw">factor</span>(df.sc<span class="op">$</span>group_i)))[, <span class="dv">2</span>]
}</code></pre></div>
<p>Check the data frame structure.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pc &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">with</span>(df.sc, <span class="kw">prop.table</span>(<span class="kw">table</span>(Cultivar)) <span class="op">*</span><span class="st"> </span><span class="dv">100</span>), <span class="dv">2</span>)
dist &lt;-<span class="st"> </span><span class="kw">with</span>(df.sc, <span class="kw">cbind</span>(<span class="dt">freq =</span> <span class="kw">table</span>(Cultivar), <span class="dt">percentage =</span> pc))
dist &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">cbind</span>(dist, <span class="kw">rownames</span>(dist)))
<span class="kw">colnames</span>(dist)[<span class="dv">3</span>] &lt;-<span class="st"> &quot;Cultivar&quot;</span>
dist<span class="op">$</span>freq &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">as.character</span>(dist<span class="op">$</span>freq))
dist <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(freq)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">10</span>) <span class="co"># or discard the last part to see all.</span></code></pre></div>
<pre><code>##    freq percentage       Cultivar
## 1   560      16.56       Goldrush
## 2   367      10.85       Superior
## 3   346      10.23        FL 1207
## 4   258       7.63      Chieftain
## 5   189       5.59       Kennebec
## 6   188       5.56        Snowden
## 7   184       5.44       Atlantic
## 8   183       5.41        FL 1533
## 9   165       4.88 Coastal Russet
## 10  112       3.31        Shepody</code></pre>
</div>
<div id="machine-learning" class="section level2">
<h2><span class="header-section-number">3.2</span> Machine learning</h2>
<p>Partioning data in Train and Test (evaluation) sets.</p>
<p>Load libraries for machine learning functions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&#39;caret&#39;</span>)
<span class="kw">library</span>(<span class="st">&#39;kknn&#39;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">853739</span>) <span class="co"># random.org</span>
split_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(df.sc<span class="op">$</span>yieldClass,
                                   <span class="dt">group =</span> <span class="st">&quot;Cultivar&quot;</span>,
                                   <span class="dt">p =</span> <span class="fl">0.75</span>,
                                   <span class="dt">list =</span> <span class="ot">FALSE</span>,
                                   <span class="dt">times =</span> <span class="dv">1</span>)
train &lt;-<span class="st"> </span>df.sc[split_index, ]
test &lt;-<span class="st"> </span>df.sc[<span class="op">-</span>split_index, ]

## With clr coordinates
ml_clr &lt;-<span class="st"> </span><span class="kw">c</span>(clrNo, <span class="st">&#39;yieldClass&#39;</span>)
train_clr =<span class="st"> </span>train[, ml_clr]
test_clr =<span class="st"> </span>test[, ml_clr]

## With clr and maturity classes
ml_mc &lt;-<span class="st"> </span><span class="kw">c</span>(clrNo, <span class="st">&#39;Maturity5&#39;</span>, <span class="st">&#39;yieldClass&#39;</span>)
train_mc =<span class="st"> </span>train[, ml_mc]
test_mc =<span class="st"> </span>test[, ml_mc]

## With clr and ionomic groups
ml_grp &lt;-<span class="st"> </span><span class="kw">c</span>(clrNo, <span class="st">&#39;group_i&#39;</span>, <span class="st">&#39;yieldClass&#39;</span>)
train_grp =<span class="st"> </span>train[, ml_grp]
test_grp =<span class="st"> </span>test[, ml_grp]</code></pre></div>
<p>The knn model will be trained on a grid.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grid &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(<span class="dt">kmax =</span> <span class="kw">c</span>(<span class="dv">7</span>,<span class="dv">9</span>,<span class="dv">12</span>,<span class="dv">15</span>),    <span class="co"># neighborhood</span>
                     <span class="dt">distance =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,         <span class="co"># 1 for euclidean distance, 2 for Mahalannobis</span>
                     <span class="dt">kernel =</span> <span class="st">&quot;optimal&quot;</span>)
grid</code></pre></div>
<pre><code>##   kmax distance  kernel
## 1    7        1 optimal
## 2    9        1 optimal
## 3   12        1 optimal
## 4   15        1 optimal
## 5    7        2 optimal
## 6    9        2 optimal
## 7   12        2 optimal
## 8   15        2 optimal</code></pre>
<p>The models will be train with a <code>10-fold cross-validation (cv)</code> based on <code>accuracy</code> as loss function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="dt">number =</span> <span class="dv">10</span>)
metric &lt;-<span class="st"> &quot;Accuracy&quot;</span></code></pre></div>
<p>Train Models:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># a) Non-linear algorithm</span>
## kNN
<span class="kw">set.seed</span>(<span class="dv">7</span>)
kknn_clr &lt;-<span class="st"> </span><span class="kw">train</span>(yieldClass <span class="op">~</span>., <span class="dt">data =</span> train_clr, <span class="dt">method =</span> <span class="st">&quot;kknn&quot;</span>, 
                  <span class="dt">metric =</span> metric, <span class="dt">trControl =</span> control, <span class="dt">tuneGrid =</span> grid)
kknn_mc &lt;-<span class="st"> </span><span class="kw">train</span>(yieldClass <span class="op">~</span>., <span class="dt">data =</span> train_mc, <span class="dt">method =</span> <span class="st">&quot;kknn&quot;</span>, 
                 <span class="dt">metric =</span> metric, <span class="dt">trControl =</span> control, <span class="dt">tuneGrid =</span> grid)
kknn_grp &lt;-<span class="st"> </span><span class="kw">train</span>(yieldClass <span class="op">~</span>., <span class="dt">data =</span> train_grp, <span class="dt">method =</span> <span class="st">&quot;kknn&quot;</span>, 
                  <span class="dt">metric =</span> metric, <span class="dt">trControl =</span> control, <span class="dt">tuneGrid =</span> grid)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># b) Advanced algorithms</span>
## SVM
<span class="kw">set.seed</span>(<span class="dv">7</span>)
svm_clr &lt;-<span class="st"> </span><span class="kw">train</span>(yieldClass <span class="op">~</span>., <span class="dt">data =</span> train_clr, <span class="dt">method =</span> <span class="st">&quot;svmRadial&quot;</span>, 
                 <span class="dt">metric =</span> metric, <span class="dt">trControl =</span> control)
svm_mc &lt;-<span class="st"> </span><span class="kw">train</span>(yieldClass <span class="op">~</span>., <span class="dt">data =</span> train_mc, <span class="dt">method =</span> <span class="st">&quot;svmRadial&quot;</span>, 
                <span class="dt">metric =</span> metric, <span class="dt">trControl =</span> control)
svm_grp &lt;-<span class="st"> </span><span class="kw">train</span>(yieldClass <span class="op">~</span>., <span class="dt">data =</span> train_grp, <span class="dt">method =</span> <span class="st">&quot;svmRadial&quot;</span>, 
                 <span class="dt">metric =</span> metric, <span class="dt">trControl =</span> control)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Random Forest
<span class="kw">set.seed</span>(<span class="dv">7</span>)
rf_clr &lt;-<span class="st"> </span><span class="kw">train</span>(yieldClass <span class="op">~</span>., <span class="dt">data =</span> train_clr, <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="dt">metric =</span> metric, <span class="dt">trControl =</span> control)
rf_mc &lt;-<span class="st"> </span><span class="kw">train</span>(yieldClass <span class="op">~</span>., <span class="dt">data =</span> train_mc, <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="dt">metric =</span> metric, <span class="dt">trControl =</span> control)
rf_grp &lt;-<span class="st"> </span><span class="kw">train</span>(yieldClass <span class="op">~</span>., <span class="dt">data =</span> train_grp, <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="dt">metric =</span> metric, <span class="dt">trControl =</span> control)</code></pre></div>
</div>
<div id="assessing-goodness-of-fit" class="section level2">
<h2><span class="header-section-number">3.3</span> Assessing goodness of fit</h2>
<p>Models results, to select the best model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Summary results</span>
results &lt;-<span class="st"> </span><span class="kw">resamples</span>(<span class="kw">list</span>(<span class="dt">kknn_clr_solely =</span> kknn_clr, 
                          <span class="dt">kknn_clr_and_ionomicgroup =</span> kknn_grp, 
                          <span class="dt">kknn_clr_and_maturityclass =</span> kknn_mc,
                          
                          <span class="dt">svm_clr_solely =</span> svm_clr, 
                          <span class="dt">svm_clr_and_ionomicgroup =</span> svm_grp, 
                          <span class="dt">svm_clr_and_maturityclass =</span> svm_mc,
                          
                          <span class="dt">rf_clr_solely =</span> rf_clr, 
                          <span class="dt">rf_clr_and_ionomicgroup =</span> rf_grp, 
                          <span class="dt">rf_clr_and_maturityclass =</span> rf_mc))

<span class="co">#summary(results) with dotplot()</span>
<span class="kw">options</span>(<span class="dt">repr.plot.width =</span> <span class="dv">5</span>, <span class="dt">repr.plot.height =</span> <span class="dv">4</span>)
<span class="kw">dotplot</span>(results)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ml-traindotplot"></span>
<img src="2019_Bookdown_files/figure-html/ml-traindotplot-1.png" alt="Comparison of models accuracies at training." width="100%" />
<p class="caption">
Figure 3.1: Comparison of models accuracies at training.
</p>
</div>
<p>Check the best model at training, but only accuracies with test sets are used as models quality metric.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">models_acc &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Model =</span> <span class="kw">summary</span>(results)<span class="op">$</span>models,
                       <span class="dt">Accuracy =</span> <span class="kw">c</span>(<span class="kw">confusionMatrix</span>(train_clr<span class="op">$</span>yieldClass, <span class="kw">predict</span>(kknn_clr))<span class="op">$</span>overall[<span class="dv">1</span>],
                                    <span class="kw">confusionMatrix</span>(train_grp<span class="op">$</span>yieldClass, <span class="kw">predict</span>(kknn_grp))<span class="op">$</span>overall[<span class="dv">1</span>],
                                    <span class="kw">confusionMatrix</span>(train_mc<span class="op">$</span>yieldClass, <span class="kw">predict</span>(kknn_mc))<span class="op">$</span>overall[<span class="dv">1</span>],
                        
                                    <span class="kw">confusionMatrix</span>(train_clr<span class="op">$</span>yieldClass, <span class="kw">predict</span>(svm_clr))<span class="op">$</span>overall[<span class="dv">1</span>],
                                    <span class="kw">confusionMatrix</span>(train_grp<span class="op">$</span>yieldClass, <span class="kw">predict</span>(svm_grp))<span class="op">$</span>overall[<span class="dv">1</span>],
                                    <span class="kw">confusionMatrix</span>(train_mc<span class="op">$</span>yieldClass, <span class="kw">predict</span>(svm_mc))<span class="op">$</span>overall[<span class="dv">1</span>],
                                
                                    <span class="kw">confusionMatrix</span>(train_clr<span class="op">$</span>yieldClass, <span class="kw">predict</span>(rf_clr))<span class="op">$</span>overall[<span class="dv">1</span>],
                                    <span class="kw">confusionMatrix</span>(train_grp<span class="op">$</span>yieldClass, <span class="kw">predict</span>(rf_grp))<span class="op">$</span>overall[<span class="dv">1</span>],
                                    <span class="kw">confusionMatrix</span>(train_mc<span class="op">$</span>yieldClass, <span class="kw">predict</span>(rf_mc))<span class="op">$</span>overall[<span class="dv">1</span>]))

models_acc[<span class="kw">order</span>(models_acc[,<span class="st">&quot;Accuracy&quot;</span>], <span class="dt">decreasing =</span> <span class="ot">TRUE</span>), ]</code></pre></div>
<pre><code>##                        Model  Accuracy
## 7              rf_clr_solely 0.9795034
## 8    rf_clr_and_ionomicgroup 0.9795034
## 9   rf_clr_and_maturityclass 0.9795034
## 2  kknn_clr_and_ionomicgroup 0.8876626
## 3 kknn_clr_and_maturityclass 0.8683484
## 1            kknn_clr_solely 0.8588885
## 6  svm_clr_and_maturityclass 0.6980686
## 5   svm_clr_and_ionomicgroup 0.6838786
## 4             svm_clr_solely 0.6637761</code></pre>
<p>Quality metrics with test (evaluation) set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predicted_kknn_clr &lt;-<span class="st"> </span><span class="kw">predict</span>(kknn_clr, test_clr)
predicted_kknn_mc &lt;-<span class="st"> </span><span class="kw">predict</span>(kknn_mc, test_mc)
predicted_kknn_grp &lt;-<span class="st"> </span><span class="kw">predict</span>(kknn_grp, test_grp)

predicted_svm_clr &lt;-<span class="st"> </span><span class="kw">predict</span>(svm_clr, test_clr)
predicted_svm_mc &lt;-<span class="st"> </span><span class="kw">predict</span>(svm_mc, test_mc)
predicted_svm_grp &lt;-<span class="st"> </span><span class="kw">predict</span>(svm_grp, test_grp)

predicted_rf_clr &lt;-<span class="st"> </span><span class="kw">predict</span>(rf_clr, test_clr)
predicted_rf_mc &lt;-<span class="st"> </span><span class="kw">predict</span>(rf_mc, test_mc)
predicted_rf_grp &lt;-<span class="st"> </span><span class="kw">predict</span>(rf_grp, test_grp)

<span class="co">#The best model</span>

tests_acc &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Model =</span> <span class="kw">summary</span>(results)<span class="op">$</span>models,
                        <span class="dt">Accuracy_on_test =</span> <span class="kw">c</span>(
                                    <span class="kw">confusionMatrix</span>(test_clr<span class="op">$</span>yieldClass, predicted_kknn_clr)<span class="op">$</span>overall[<span class="dv">1</span>],
                                    <span class="kw">confusionMatrix</span>(test_grp<span class="op">$</span>yieldClass, predicted_kknn_grp)<span class="op">$</span>overall[<span class="dv">1</span>],
                                    <span class="kw">confusionMatrix</span>(test_mc<span class="op">$</span>yieldClass, predicted_kknn_mc)<span class="op">$</span>overall[<span class="dv">1</span>],
                        
                                    <span class="kw">confusionMatrix</span>(test_clr<span class="op">$</span>yieldClass, predicted_svm_clr)<span class="op">$</span>overall[<span class="dv">1</span>],
                                    <span class="kw">confusionMatrix</span>(test_grp<span class="op">$</span>yieldClass, predicted_svm_grp)<span class="op">$</span>overall[<span class="dv">1</span>],
                                    <span class="kw">confusionMatrix</span>(test_mc<span class="op">$</span>yieldClass, predicted_svm_mc)<span class="op">$</span>overall[<span class="dv">1</span>],
                                
                                    <span class="kw">confusionMatrix</span>(test_clr<span class="op">$</span>yieldClass, predicted_rf_clr)<span class="op">$</span>overall[<span class="dv">1</span>],
                                    <span class="kw">confusionMatrix</span>(test_grp<span class="op">$</span>yieldClass, predicted_rf_grp)<span class="op">$</span>overall[<span class="dv">1</span>],
                                    <span class="kw">confusionMatrix</span>(test_mc<span class="op">$</span>yieldClass, predicted_rf_mc)<span class="op">$</span>overall[<span class="dv">1</span>]))
tests_acc[<span class="kw">order</span>(tests_acc[,<span class="st">&quot;Accuracy_on_test&quot;</span>], <span class="dt">decreasing =</span> <span class="ot">TRUE</span>), ]</code></pre></div>
<pre><code>##                        Model Accuracy_on_test
## 9   rf_clr_and_maturityclass        0.7254438
## 8    rf_clr_and_ionomicgroup        0.7183432
## 3 kknn_clr_and_maturityclass        0.7053254
## 7              rf_clr_solely        0.7029586
## 1            kknn_clr_solely        0.6828402
## 2  kknn_clr_and_ionomicgroup        0.6816568
## 6  svm_clr_and_maturityclass        0.6721893
## 5   svm_clr_and_ionomicgroup        0.6639053
## 4             svm_clr_solely        0.6568047</code></pre>
<p>Yield Class Prediction with rf algorithm on test set</p>
<p>Order prediction quality metric by cultivar with <code>rf</code> combining clr values and new clustered variable (<code>rf_clr_and_ionomicgroup</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test<span class="op">$</span>ypred =<span class="st"> </span>predicted_rf_grp <span class="co"># adds predictions to test set</span>

cultivar_acc &lt;-<span class="st"> </span>test <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(Cultivar) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">do</span>(<span class="dt">Accuracy =</span> <span class="kw">as.numeric</span>(<span class="kw">confusionMatrix</span>(.<span class="op">$</span>yieldClass, .<span class="op">$</span>ypred)<span class="op">$</span>overall[<span class="dv">1</span>]),
       <span class="dt">N_obs =</span> <span class="kw">as.numeric</span>(<span class="kw">nrow</span>(.)))

cultivar_acc<span class="op">$</span>Accuracy &lt;-<span class="st"> </span><span class="kw">unlist</span>(cultivar_acc<span class="op">$</span>Accuracy)
cultivar_acc<span class="op">$</span>N_obs &lt;-<span class="st"> </span><span class="kw">unlist</span>(cultivar_acc<span class="op">$</span>N_obs)

data =<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">subset</span>(cultivar_acc, Accuracy<span class="op">&gt;</span><span class="dv">0</span>))
data[<span class="kw">order</span>(data[,<span class="st">&quot;Accuracy&quot;</span>], <span class="dt">decreasing=</span>T), ]</code></pre></div>
<pre><code>##              Cultivar  Accuracy N_obs
## 12 Dark Red Chieftain 1.0000000     2
## 18            Harmony 1.0000000     1
## 19             Kanona 1.0000000     1
## 21         Keuka Gold 1.0000000     1
## 22             Lamoka 1.0000000     2
## 25            Norland 1.0000000    12
## 26          Peribonka 1.0000000     2
## 29          Red Cloud 1.0000000     4
## 35              Sifra 1.0000000     2
## 40             W 1386 1.0000000     4
## 41             Waneta 1.0000000     3
## 10          Chieftain 0.8260870    69
## 34            Shepody 0.8214286    28
## 24            Mystere 0.8125000    16
## 6               Argos 0.8000000     5
## 33     Russet Norkota 0.8000000     5
## 14            FL 1207 0.7872340    94
## 17           Goldrush 0.7746479   142
## 20           Kennebec 0.7727273    44
## 2          AC Chaleur 0.7500000     4
## 4             Andover 0.7500000     8
## 31               Roko 0.7500000     4
## 32     Russet Burbank 0.7500000     8
## 11     Coastal Russet 0.7352941    34
## 27         Pommerelle 0.7142857     7
## 36            Snowden 0.6923077    39
## 9            Carolina 0.6666667     3
## 30          Red Maria 0.6666667     3
## 15            FL 1533 0.6607143    56
## 37           Superior 0.6288660    97
## 1          AC Belmont 0.6250000    16
## 39            Vivaldi 0.6000000     5
## 7            Atlantic 0.5769231    52
## 42         Yukon Gold 0.5555556    18
## 5             Aquilon 0.5263158    19
## 3               Ambra 0.5000000     2
## 8         Bijou Rouge 0.5000000     2
## 13             Estima 0.5000000    12
## 16    Frontier Russet 0.5000000     4
## 28               Reba 0.5000000     4
## 23            Lanorma 0.3333333     3
## 38             Viking 0.3333333     3</code></pre>
<p>Check it with <code>geom_segment()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">options</span>(<span class="dt">repr.plot.width =</span> <span class="dv">8</span>, <span class="dt">repr.plot.height =</span> <span class="dv">4</span>)
<span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="kw">reorder</span>(Cultivar, Accuracy), Accuracy)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color=</span><span class="kw">cut</span>(Accuracy, <span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.70</span>, <span class="fl">0.90</span>, <span class="dv">1</span>)))) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Cultivar, <span class="dt">xend=</span>Cultivar, <span class="dt">y=</span><span class="dv">0</span>, <span class="dt">yend=</span>Accuracy, 
                     <span class="dt">color=</span><span class="kw">cut</span>(Accuracy, <span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.70</span>, <span class="fl">0.90</span>, <span class="dv">1</span>))), <span class="dt">size=</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Cultivar&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">legend.title=</span><span class="kw">element_blank</span>(),
          <span class="dt">axis.text.x=</span><span class="kw">element_text</span>(<span class="dt">angle=</span><span class="dv">90</span>, <span class="dt">hjust=</span><span class="dv">1</span>))<span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">text=</span><span class="kw">element_text</span>(<span class="dt">family=</span><span class="st">&quot;Arial&quot;</span>, <span class="dt">face=</span><span class="st">&quot;bold&quot;</span>, <span class="dt">size=</span><span class="dv">12</span>))</code></pre></div>
<div class="figure" style="text-align: center">
<img src="2019_Bookdown_files/figure-html/accuracy_cultivar-1.png" alt="Predictive accuracy for cultivars." width="100%" />
<p class="caption">
(#fig:accuracy_cultivar)Predictive accuracy for cultivars.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#ggsave(&quot;images/cultivAcc.tiff&quot;, width=8, height=3)</span></code></pre></div>
<p>Run the Chi-square homogenity test to compare prediction with a non-informative classification consisting of an equal distribution of 50% successful and 50% unsuccessful cases, using kknn.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cm &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(predicted_kknn_grp, test_grp<span class="op">$</span>yieldClass) <span class="co"># confusion matrix</span>
cm<span class="op">$</span>table</code></pre></div>
<pre><code>##           Reference
## Prediction  HY  LY
##         HY 206 142
##         LY 127 370</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Model&#39;s classification</span>
good_class &lt;-<span class="st"> </span>cm<span class="op">$</span>table[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">+</span>cm<span class="op">$</span>table[<span class="dv">2</span>,<span class="dv">2</span>] <span class="co"># HY or LY and correctly predicted</span>
misclass &lt;-<span class="st"> </span>cm<span class="op">$</span>table[<span class="dv">1</span>,<span class="dv">2</span>]<span class="op">+</span>cm<span class="op">$</span>table[<span class="dv">2</span>,<span class="dv">1</span>]   <span class="co"># wrong classification</span>
ml_class &lt;-<span class="st"> </span><span class="kw">c</span>(good_class, misclass)

<span class="co"># Non-informative model</span>
total &lt;-<span class="st"> </span><span class="kw">sum</span>(cm<span class="op">$</span>table)                    <span class="co"># number of samples</span>
good_nim &lt;-<span class="st"> </span><span class="fl">0.50</span> <span class="op">*</span><span class="st"> </span>total
misclass_nim &lt;-<span class="st"> </span><span class="fl">0.50</span> <span class="op">*</span><span class="st"> </span>total
non_inf_model &lt;-<span class="st"> </span><span class="kw">c</span>(good_nim, misclass_nim)

<span class="co"># Matrix for chisquare test</span>
m &lt;-<span class="st"> </span><span class="kw">rbind</span>(ml_class, non_inf_model)
m</code></pre></div>
<pre><code>##                [,1]  [,2]
## ml_class      576.0 269.0
## non_inf_model 422.5 422.5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># chisq.test</span>
khi2_test &lt;-<span class="st"> </span><span class="kw">chisq.test</span>(m)
khi2_test</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  m
## X-squared = 56.923, df = 1, p-value = 4.533e-14</code></pre>
<p>The null hypothesis for a non-informative classification is rejected after the chi-square homogeneity test.</p>
<p>The train data set with predicted yield classes <code>train_df</code> backup will be used to test perturbation vector theory in the next file.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_yield &lt;-<span class="st"> </span><span class="kw">predict</span>(rf_grp, train_grp)
train_df =<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">cbind</span>(df[split_index, ], pred_yield))
<span class="kw">write_csv</span>(train_df, <span class="st">&quot;output/train_df.csv&quot;</span>)
<span class="kw">nrow</span>(train_df)</code></pre></div>
<pre><code>## [1] 2537</code></pre>
<p>True Negatives (TN) specimens in this study are observations of the training data set with high yield (HY) and correctly predicted. Compute clr centroids for True Negatives <code>with original</code> clr values; use original data frame <code>df</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">TNs =<span class="st"> </span>train_df[train_df<span class="op">$</span>yieldClass <span class="op">==</span><span class="st"> &#39;HY&#39;</span> <span class="op">&amp;</span><span class="st"> </span>pred_yield <span class="op">==</span><span class="st"> &#39;HY&#39;</span>, ]
<span class="kw">nrow</span>(TNs)</code></pre></div>
<pre><code>## [1] 988</code></pre>
<p>The next cell computes clr balances Centroids for ionomic groups.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">TNmedianNorms &lt;-<span class="st"> </span>TNs <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(group_i) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(clrNo) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_all</span>(<span class="kw">list</span>(median))</code></pre></div>
<pre><code>## Adding missing grouping variables: `group_i`</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">TNmedianNorms</code></pre></div>
<pre><code>## # A tibble: 6 x 7
##   group_i  clrN  clrP  clrK clrMg  clrCa clrFv
##   &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1 1       0.727 -1.98 0.512 -1.82 -0.979  3.56
## 2 2       0.910 -1.93 0.532 -1.92 -1.14   3.57
## 3 3       0.894 -2.22 0.359 -1.60 -1.20   3.83
## 4 4       0.747 -1.97 0.219 -1.48 -1.04   3.50
## 5 5       0.601 -2.20 0.507 -1.60 -0.823  3.40
## 6 6       0.712 -2.02 0.640 -2.13 -0.837  3.61</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chapter-Clustering.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Chapter-Perturbation-vector.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["2019_Bookdown.pdf", "2019_Bookdown.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
